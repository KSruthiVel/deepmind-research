# DeepMind Open-Source Resources

This document provides a comprehensive list of our open-source contributions environments, datasets, and codeâ€”designed to facilitate collaboration and accelerate scientific progress. All resources are hosted at [github.com/google-deepmind](https://github.com/google-deepmind) unless otherwise noted.

## Open-Source Environments
These environments offer diverse platforms for AI research, spanning simulations, games, and multi-agent systems.

- **[DeepMind Lab](https://github.com/google-deepmind/lab)**  
  A 3D environment for developing and testing AI agents in navigation and problem-solving tasks.

- **[DeepMind Lab2D](https://github.com/google-deepmind/lab2d)**  
  A framework for creating 2D grid-world environments with text-based maps and multi-agent support.

- **[DeepMind Control Suite](https://github.com/google-deepmind/dm_control)**  
  A set of continuous control tasks built on MuJoCo, providing benchmarks for reinforcement learning.

- **[OpenSpiel](https://github.com/google-deepmind/open_spiel)**  
  A library of game environments and algorithms for single- and multi-agent reinforcement learning.

- **[Melting Pot](https://github.com/google-deepmind/meltingpot)**  
  A multi-agent RL suite with scenarios to evaluate social generalization in cooperative and competitive settings.

- **[MuJoCo](https://github.com/google-deepmind/mujoco)**  
  A physics engine for high-fidelity simulations, foundational for robotics and control research.

- **[StarCraft II Learning Environment (PySC2)](https://github.com/google-deepmind/pysc2)**  
  A Python interface to StarCraft II for AI research in real-time strategy scenarios.

- **[AndroidEnv](https://github.com/google-deepmind/android_env)**  
  An environment for training AI agents on Android device interactions.

- **[bsuite](https://github.com/google-deepmind/bsuite)**  
  A collection of experiments to assess core capabilities of reinforcement learning algorithms.

## Open-Source Datasets
These datasets provide high-quality data for training and evaluating AI models across various domains.

- **[DeepMind Kinetics](https://arxiv.org/abs/1705.06950)**  
  A video dataset for action recognition, featuring human activities from YouTube (includes I3D model code).

- **[CodeContests](https://github.com/google-deepmind/code_contests)**  
  A collection of competitive programming problems and solutions to support code-generation research.

- **[Open X-Embodiment](https://github.com/google-deepmind/open_x_embodiment)**  
  A unified robotics dataset with real-world trajectories from multiple robot types, standardized for reuse.

- **[NarrativeQA](https://github.com/google-deepmind/narrativeqa)**  
  A dataset of full-length narratives with question-answer pairs for reading comprehension research.

- **[AlphaFold Protein Structure Database](https://alphafold.ebi.ac.uk/)**  
  A comprehensive database of predicted protein structures, freely available for biological research.

- **[Mathematics Dataset](https://github.com/google-deepmind/mathematics_dataset)**  
  A dataset of mathematical question-answer pairs for training AI in symbolic reasoning.

## Open-Source Code
These libraries and implementations provide tools for building and advancing AI systems.

- **[AlphaFold](https://github.com/google-deepmind/alphafold)**  
  The implementation of our protein structure prediction system, including models and workflows.

- **[Optax](https://github.com/google-deepmind/optax)**  
  A JAX-based library for gradient processing and optimization in neural network training.

- **[Haiku](https://github.com/google-deepmind/dm-haiku)**  
  A neural network library for JAX, offering an intuitive and flexible design.

- **[Acme](https://github.com/google-deepmind/acme)**  
  A framework for reinforcement learning research with modular agent implementations.

- **[Sonnet](https://github.com/google-deepmind/sonnet)**  
  A TensorFlow library for constructing modular neural networks.

- **[Deep Q-Network (DQN)](https://github.com/google-deepmind/dqn)**  
  An implementation of the foundational reinforcement learning algorithm.

- **[Differential Neural Computer (DNC)](https://github.com/google-deepmind/dnc)**  
  A memory-augmented neural network implementation.

- **[Graph Nets](https://github.com/google-deepmind/graph_nets)**  
  A TensorFlow library for building graph neural networks.

- **[RLax](https://github.com/google-deepmind/rlax)**  
  A library of reinforcement learning components for JAX.

- **[Chex](https://github.com/google-deepmind/chex)**  
  Utilities for testing and debugging JAX code.

- **[Jraph](https://github.com/google-deepmind/jraph)**  
  A library for graph neural networks in JAX.

- **[Mctx](https://github.com/google-deepmind/mctx)**  
  A Monte Carlo Tree Search implementation for reinforcement learning planning.

- **[Launchpad](https://github.com/google-deepmind/launchpad)**  
  A framework for distributed reinforcement learning experiments.

- **[Reverb](https://github.com/google-deepmind/reverb)**  
  An efficient replay buffer system for reinforcement learning agents.

- **[XManager](https://github.com/google-deepmind/xmanager)**  
  A tool for managing distributed AI experiments.

- **[FunSearch](https://github.com/google-deepmind/funsearch)**  
  Code for function search in mathematical discovery research.

- **[Gemma](https://github.com/google-deepmind/gemma)**  
  A family of open-weight language models (1B to 27B parameters) with a Python/JAX API.

- **[TapNet](https://github.com/google-deepmind/tapnet)**  
  Task-Agnostic Policy Network for robotics and control tasks.

- **[PGMax](https://github.com/google-deepmind/pgmax)**  
  A probabilistic graphical model inference library.
